{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAOUE1zNesIW"
   },
   "outputs": [],
   "source": [
    "#Imports of libraries required\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "y3F06fgxfQPJ",
    "outputId": "14a4b17a-91ff-466d-a686-b259b4d2ad9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 1.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=530ce9fae71c7fe3cf9f02d3e2a6c8474afbd7f36afda3848d8510e543665171\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from time import time\n",
    "!pip install emoji\n",
    "from emoji import demojize\n",
    "\n",
    "#preprocessing function (The preprocessing functions in old_dataset_data_and_model folder can also be used)\n",
    "def preprocess(texts, quiet=False):\n",
    "  start = time()\n",
    "  # Lowercasing\n",
    "  texts = texts.str.lower()\n",
    "\n",
    "  # Remove special chars\n",
    "  texts = texts.str.replace(r\"(http|@)\\S+\", \"\")\n",
    "  texts = texts.apply(demojize)\n",
    "  texts = texts.str.replace(r\"::\", \": :\")\n",
    "  texts = texts.str.replace(r\"’\", \"'\")\n",
    "  texts = texts.str.replace(r\"[^a-z\\':_]\", \" \")\n",
    "\n",
    "  # Remove repetitions\n",
    "  pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
    "  texts = texts.str.replace(pattern, r\"\\1\")\n",
    "\n",
    "  # Transform short negation form\n",
    "  texts = texts.str.replace(r\"(can't|cannot)\", 'can not')\n",
    "  texts = texts.str.replace(r\"n't\", ' not')\n",
    "\n",
    "  # Remove stop words\n",
    "  stopwords = nltk.corpus.stopwords.words('english')\n",
    "  stopwords.remove('not')\n",
    "  stopwords.remove('nor')\n",
    "  stopwords.remove('no')\n",
    "  texts = texts.apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in stopwords])\n",
    "  )\n",
    "\n",
    "  if not quiet:\n",
    "    print(\"Time to clean up: {:.2f} sec\".format(time() - start))\n",
    "\n",
    "  return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rmxSR04--iU"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Stemming preprocessing function\n",
    "'''\n",
    "from nltk.stem.porter import *\n",
    "def stem(tokenized_text):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    stemmed_text = []\n",
    "    for tx in tokenized_text:\n",
    "        tx = stemmer.stem(tx)\n",
    "        stemmed_text.append(tx)\n",
    "#     print(stemmed_text)\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2lXbTYce4Cb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "#Dataset class\n",
    "class Dataset:\n",
    "  def __init__(self, filename, label_col='label', text_col='text'):\n",
    "    self.filename = filename\n",
    "    self.label_col = label_col\n",
    "    self.text_col = text_col\n",
    "\n",
    "  @property\n",
    "  def data(self):\n",
    "    data = self.dataframe[[self.label_col, self.text_col]].copy()\n",
    "    data.columns = ['label', 'text']\n",
    "    return data\n",
    "\n",
    "  @property\n",
    "  def cleaned_data(self):\n",
    "    data =  self.dataframe[[self.label_col, 'cleaned']]\n",
    "    data.columns = ['label', 'text']\n",
    "    return data\n",
    "\n",
    "  def load(self):\n",
    "    df = pd.read_csv(Path(self.filename).resolve())\n",
    "    self.dataframe = df\n",
    "\n",
    "  def preprocess_texts(self, quiet=False):\n",
    "    self.dataframe['cleaned'] = preprocess(self.dataframe[self.text_col], quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_N5m4ed8fLfl",
    "outputId": "aa47a186-49e9-4034-ad3e-098b6840292b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up: 62.04 sec\n"
     ]
    }
   ],
   "source": [
    "#Loading of dataset file and preprocessing \n",
    "dataset_path = Path('dataset.csv').resolve()\n",
    "dataset = Dataset(dataset_path)\n",
    "dataset.load()\n",
    "dataset.preprocess_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7gtGRUYgfipA",
    "outputId": "4454abf9-9286-4878-95af-5d76c45da9f4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>happy valentines ma'am missyou poo:red_heart:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joy</td>\n",
       "      <td>:red_heart: happy announce today liverpool hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>onyghad cutie sadya :red_heart:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>joy</td>\n",
       "      <td>memoire spirit hearts day flows love love ones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joy</td>\n",
       "      <td>love you:pleading_face: :red_heart: :red_heart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   joy      happy valentines ma'am missyou poo:red_heart:\n",
       "1   joy  :red_heart: happy announce today liverpool hea...\n",
       "2   joy                    onyghad cutie sadya :red_heart:\n",
       "3   joy  memoire spirit hearts day flows love love ones...\n",
       "4   joy  love you:pleading_face: :red_heart: :red_heart..."
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cleaned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VC6tILvFf8RS"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yn6bSFZDgDEw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3dQ5l-VgNua"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJY3kzcWfRgC"
   },
   "outputs": [],
   "source": [
    "#Loading of data\n",
    "data = dataset.cleaned_data.copy()\n",
    "#with open('prodata4.pkl', 'rb') as pickle_file:\n",
    "#    data4 = pickle.load(pickle_file)\n",
    "\n",
    "#with open('prodata3.pkl', 'rb') as pickle_file:\n",
    "#    data3 = pickle.load(pickle_file)\n",
    "\n",
    "#data = data[data.label!='joy']\n",
    "\n",
    "#data3['sentiment'] = data3['sentiment'].apply(\n",
    "#      lambda x: 'joy' if x == 4 else ('surprise' if x == 3 else ('sadness' if x == 2 else ('fear' if x == 1  else 'anger'))))\n",
    "\n",
    "#data4=data4.rename(columns={\"content\":\"text\"})\n",
    "#data4=data4[data4.label!='surprise']\n",
    "#data4=data4[data4.label!='disgust']\n",
    "#data4=data4[data4.label!='guilt']\n",
    "#data4=data4[data4.label!='shame']\n",
    "#data3=data3.rename(columns={\"content\":\"text\", \"sentiment\":\"label\"})\n",
    "#data3=data3[data3.label!='surprise']\n",
    "#print(data4.label.unique())\n",
    "#print(data4.label.value_counts())\n",
    "#print(data1.head())\n",
    "#frames = [data,data3,data4]\n",
    "#data = pd.concat(frames)\n",
    "#data = data.sample(frac=1)\n",
    "#print(data.text.map(lambda x: len(x.split())).max())\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BX1zqxWD6HrC"
   },
   "outputs": [],
   "source": [
    "#Tokenizing on the dataset\n",
    "num_words = 16638\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, lower=True)\n",
    "tokenizer.fit_on_texts(data.text)\n",
    "\n",
    "file_to_save = Path('tokenizer.pickle').resolve()\n",
    "with file_to_save.open('wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "E9hDm90E5-dk",
    "outputId": "2ab8b19a-0772-4c4b-9f3f-42842c7b6a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'fear' 'anger' 'sadness']\n",
      "joy        43000\n",
      "anger      41440\n",
      "fear       40093\n",
      "sadness    37509\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.label.unique())\n",
    "print(data.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2nRtEOl7yHC"
   },
   "outputs": [],
   "source": [
    "#Resampling of data (here the data of joy emotion)\n",
    "from sklearn.utils import resample\n",
    "joy_data = resample(data[data.label=='joy'],replace=True,n_samples=30000,random_state=27)\n",
    "data = data[data.label!='joy']\n",
    "data = data.append(joy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "xtrw4bdy8oo2",
    "outputId": "d7ef42b3-ae51-4326-96d7-8b36d3652767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fear' 'anger' 'sadness' 'joy']\n",
      "anger      41440\n",
      "fear       40093\n",
      "sadness    37509\n",
      "joy        30000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.label.unique())\n",
    "print(data.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "_PONCKs-gRhM",
    "outputId": "c1b8bc96-28b0-48e1-cbb8-2c92592fc13f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40093, 2)\n",
      "(41440, 2)\n",
      "(37509, 2)\n",
      "(30000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Splitting into training and test dataset\n",
    "train = pd.DataFrame(columns=['label', 'text'])\n",
    "validation = pd.DataFrame(columns=['label', 'text'])\n",
    "for label in data.label.unique():\n",
    "    label_data = data[data.label == label]\n",
    "    print(label_data.shape)\n",
    "    train_data, validation_data = train_test_split(label_data, test_size=0.1)\n",
    "    train = pd.concat([train, train_data])\n",
    "    validation = pd.concat([validation, validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Qg9-NhZ27ZkS",
    "outputId": "8835f17a-a3ad-4df8-997f-ba82bfd1b4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger      4144\n",
      "fear       4010\n",
      "sadness    3751\n",
      "joy        3000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(validation.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CCq3LzpgfAL-",
    "outputId": "393d3716-4b98-456a-d868-e9935135a9fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43000</th>\n",
       "      <td>fear</td>\n",
       "      <td>oh gosh :face_screaming_in_fear: :face_screami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43001</th>\n",
       "      <td>fear</td>\n",
       "      <td>what's point looking back need results ever :f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43002</th>\n",
       "      <td>fear</td>\n",
       "      <td>dot cotton: actress june brown says left easte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43003</th>\n",
       "      <td>fear</td>\n",
       "      <td>scares hell feels like players confused messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43004</th>\n",
       "      <td>fear</td>\n",
       "      <td>:face_screaming_in_fear: kaget liat notif miss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "43000  fear  oh gosh :face_screaming_in_fear: :face_screami...\n",
       "43001  fear  what's point looking back need results ever :f...\n",
       "43002  fear  dot cotton: actress june brown says left easte...\n",
       "43003  fear  scares hell feels like players confused messag...\n",
       "43004  fear  :face_screaming_in_fear: kaget liat notif miss..."
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73crPHlOgVcF"
   },
   "outputs": [],
   "source": [
    "#Keras related imports\n",
    "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dropout, GRU\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, Dense, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7IerXgG3gZIM",
    "outputId": "b167782c-a9e8-4f20-d75b-036b0e4b92f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16638\n"
     ]
    }
   ],
   "source": [
    "#Loading tokenizer\n",
    "tokenizer_path = Path('tokenizer.pickle').resolve()\n",
    "with tokenizer_path.open('rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "#Parameters of model    \n",
    "input_dim = min(tokenizer.num_words, len(tokenizer.word_index) + 1)\n",
    "num_classes = 4\n",
    "embedding_dim = 100\n",
    "input_length = 142\n",
    "lstm_units = 128\n",
    "lstm_dropout = 0.1\n",
    "recurrent_dropout = 0.1\n",
    "spatial_dropout=0.2\n",
    "filters=64\n",
    "kernel_size=4\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5t9BfwYEglNK"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "VyXlxaZ8e4lq",
    "outputId": "048a6636-01dc-472a-f2d0-0f82f021fe05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "#Glove file download\n",
    "import gensim.downloader as api\n",
    "f = api.load(\"glove-twitter-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VAxh8vokjKdh",
    "outputId": "f420a61e-b8aa-4a1c-92d1-324bc8319888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(f['cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4ZgggBNg1pE"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "train_sequences = [text.split() for text in train.text]\n",
    "validation_sequences = [text.split() for text in validation.text]\n",
    "\n",
    "\n",
    "#Glove Layer Implementation\n",
    "WV_DIM = 50\n",
    "nb_words = 16638\n",
    "# we initialize the matrix with random numbers\n",
    "glove_matrix = (np.random.rand(nb_words, WV_DIM) - 0.5) / 5.0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= 16638:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = f[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        glove_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass   \n",
    "\n",
    "'''\n",
    "#Word2Vec Layer Implementation (Uncomment this section and comment the Glove section to use Word2Vec)\n",
    "model = Word2Vec(train_sequences, size=100, window=5, min_count=5, workers=16, sg=0, negative=5)\n",
    "word_vectors = model.wv\n",
    "\n",
    "\n",
    "WV_DIM = 100\n",
    "nb_words = 16638\n",
    "# we initialize the matrix with random numbers\n",
    "wv_matrix = (np.random.rand(nb_words, WV_DIM) - 0.5) / 5.0\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= 16638:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word_vectors[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        wv_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass   \n",
    "'''\n",
    "\n",
    "#Tokenized text to sequences and padding\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(train_sequences)\n",
    "list_tokenized_validation = tokenizer.texts_to_sequences(validation_sequences)\n",
    "x_train = pad_sequences(list_tokenized_train, maxlen=input_length)\n",
    "x_validation = pad_sequences(list_tokenized_validation, maxlen=input_length)\n",
    "\n",
    "#Encoding of labels\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(data.label.unique())\n",
    "\n",
    "encoder_path = Path('/emotion_recognition', 'encoder.pickle')\n",
    "with encoder_path.open('wb') as file:\n",
    "    pickle.dump(encoder, file)\n",
    "\n",
    "y_train = encoder.transform(train.label)\n",
    "y_validation = encoder.transform(validation.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBMpl14PkU-Q"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "jPkSVFMHdX8R",
    "outputId": "4dea84db-3404-494b-e312-d048452f0fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#Our Emotion Detection Model \n",
    "input_layer = Input(shape=(input_length,))\n",
    "output_layer = Embedding(\n",
    "  input_dim=input_dim,\n",
    "  weights=[glove_matrix],\n",
    "  output_dim=50,\n",
    "  input_shape=(input_length,)\n",
    ")(input_layer)\n",
    "\n",
    "output_layer = SpatialDropout1D(spatial_dropout)(output_layer)\n",
    "\n",
    "output_layer = Bidirectional(\n",
    "LSTM(128, return_sequences=True,\n",
    "     dropout=lstm_dropout, recurrent_dropout=recurrent_dropout)\n",
    ")(output_layer)\n",
    "\n",
    "\n",
    "\n",
    "output_layer = Conv1D(filters, kernel_size=kernel_size, padding='valid',\n",
    "                    kernel_initializer='glorot_uniform')(output_layer)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(output_layer)\n",
    "max_pool = GlobalMaxPooling1D()(output_layer)\n",
    "output_layer = concatenate([avg_pool, max_pool])\n",
    "\n",
    "output_layer = Dense(num_classes, activation='softmax')(output_layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "gxgKQGyodwbk",
    "outputId": "7f560aec-b263-4e25-cae7-9bc50e9e8dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 142)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 142, 50)      831900      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 142, 50)      0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 142, 256)     183296      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 139, 64)      65600       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 64)           0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            516         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,081,312\n",
      "Trainable params: 1,081,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFlWW9luhEBD"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "40CG7Y95Fzj9",
    "outputId": "715d05dc-dd2a-41dd-e7de-daf1d53eccde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134137, 142)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "kzt3k0j0hH-B",
    "outputId": "c9a0b340-7479-46fe-ba31-099571438fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "285/285 [==============================] - 460s 2s/step - loss: 0.5153 - accuracy: 0.7872 - val_loss: 0.3136 - val_accuracy: 0.8621\n",
      "Epoch 2/12\n",
      "285/285 [==============================] - 460s 2s/step - loss: 0.3234 - accuracy: 0.8600 - val_loss: 0.2896 - val_accuracy: 0.8724\n",
      "Epoch 3/12\n",
      "285/285 [==============================] - 462s 2s/step - loss: 0.2984 - accuracy: 0.8709 - val_loss: 0.2775 - val_accuracy: 0.8803\n",
      "Epoch 4/12\n",
      "285/285 [==============================] - 462s 2s/step - loss: 0.2841 - accuracy: 0.8772 - val_loss: 0.2710 - val_accuracy: 0.8831\n",
      "Epoch 5/12\n",
      "285/285 [==============================] - 463s 2s/step - loss: 0.2729 - accuracy: 0.8824 - val_loss: 0.2689 - val_accuracy: 0.8832\n",
      "Epoch 6/12\n",
      "285/285 [==============================] - 462s 2s/step - loss: 0.2628 - accuracy: 0.8867 - val_loss: 0.2707 - val_accuracy: 0.8823\n",
      "Epoch 7/12\n",
      "285/285 [==============================] - 463s 2s/step - loss: 0.2549 - accuracy: 0.8909 - val_loss: 0.2653 - val_accuracy: 0.8855\n",
      "Epoch 8/12\n",
      "285/285 [==============================] - 462s 2s/step - loss: 0.2469 - accuracy: 0.8945 - val_loss: 0.2673 - val_accuracy: 0.8839\n",
      "Epoch 9/12\n",
      "285/285 [==============================] - 457s 2s/step - loss: 0.2385 - accuracy: 0.8985 - val_loss: 0.2677 - val_accuracy: 0.8845\n",
      "Epoch 10/12\n",
      "  3/285 [..............................] - ETA: 4:50 - loss: 0.2039 - accuracy: 0.9141"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f4790955437c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_validation, y_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iypr6wFRhNCh"
   },
   "outputs": [],
   "source": [
    "#Save model weights\n",
    "model_file = Path('model_weights88.h5').resolve()\n",
    "model.save_weights(model_file.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zss8J_C4WuCc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0rVC4TB2K7L"
   },
   "outputs": [],
   "source": [
    "#Load model weights\n",
    "model_weights_path = Path('model_weights88.h5').resolve()\n",
    "model.load_weights(model_weights_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tz40rfjGFM0b",
    "outputId": "57d5d66e-1d08-44b3-8e86-d084303f8897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up: 2.33 sec\n"
     ]
    }
   ],
   "source": [
    "#Load Test dataset\n",
    "dataset_path = Path('dataset_test.csv').resolve()\n",
    "dataset = Dataset(dataset_path)\n",
    "dataset.load()\n",
    "dataset.preprocess_texts()\n",
    "test_data = dataset.cleaned_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kIJKOT9dIIwd",
    "outputId": "fc93b6a2-4868-4dd6-f27f-d8d502e88ada"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>ether way need tht:face_with_steam_from_nose: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>tf hate oneus imma fight :face_with_steam_from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>came way uni find lecture already topic ive st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>sometimes really wanna post portraits drew rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>one hit hard :skull: :face_with_steam_from_nos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0  anger  ether way need tht:face_with_steam_from_nose: ...\n",
       "1  anger  tf hate oneus imma fight :face_with_steam_from...\n",
       "2  anger  came way uni find lecture already topic ive st...\n",
       "3  anger  sometimes really wanna post portraits drew rea...\n",
       "4  anger  one hit hard :skull: :face_with_steam_from_nos..."
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmximloeFSCn"
   },
   "outputs": [],
   "source": [
    "#Tokenization, converted to sequences and padding\n",
    "test_sequences = [text.split() for text in test_data.text]\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(test_sequences)\n",
    "x_test = pad_sequences(list_tokenized_test, maxlen=input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oO2y1rlSoq3Q"
   },
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQhP2ISEPHlf"
   },
   "outputs": [],
   "source": [
    "y_test = encoder.transform(test_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dvTsKdzyvMMQ"
   },
   "outputs": [],
   "source": [
    "y_pred = y_pred.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "JYShrN48Pg1b",
    "outputId": "422b2466-1b39-4d2a-f3d4-722de1723dd7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2c791a6681f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_labels' is not defined"
     ]
    }
   ],
   "source": [
    "print(unique_labels(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Q-9BFd2vscF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "#Plotting of Confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = unique_labels(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "uPLHS9kiwKo7",
    "outputId": "98a03cba-43ca-4b84-b266-0b3e96c6e90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[8.52092352e-01 8.87445887e-02 5.05050505e-03 5.41125541e-02]\n",
      " [1.14810563e-03 9.93111366e-01 0.00000000e+00 5.74052813e-03]\n",
      " [1.53970827e-02 1.45867099e-02 9.69205835e-01 8.10372771e-04]\n",
      " [4.86270023e-02 7.83752860e-02 2.28832952e-03 8.70709382e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plot_confusion_matrix(y_test, y_pred, normalize=True)\n",
    "fig.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoOsGsPDwi57"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TrainEmotionDetection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
